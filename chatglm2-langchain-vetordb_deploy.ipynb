{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63c0138-d19f-4109-aac5-fd0f028a5869",
   "metadata": {},
   "source": [
    "### 1.安装 HuggingFace 并下载模型到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb1a261-748a-470a-900f-1863db83447b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install huggingface-hub -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8f333d-7708-4ffc-8887-55e9bff44129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./LLM_chatglm2_model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"THUDM/chatglm2-6b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd16c8-e2f7-4d59-8d10-b763a28b6a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snapshot_download(repo_id=model_name, cache_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbeea66-a864-4403-984a-e1f86b9958ab",
   "metadata": {},
   "source": [
    "### 2.SageMaker 初始化配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0660d52d-9c07-4445-893b-d95a2227eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker import image_uris\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65185ac-7a43-4661-9fcb-7d77541a04d2",
   "metadata": {},
   "source": [
    "### 3. 把模型拷贝到 S3 存储桶为后续部署做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8cccf-f3b7-4d34-ab14-be364901c1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_model_prefix = \"LLM_chatglm2_model\"  # folder where model checkpoint will go\n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_code_prefix = \"LLM_chatglm2_deploy_code\"\n",
    "\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")\n",
    "print(f\"model_snapshot_path: {model_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068e3ed1-9a9b-4ef2-92dd-4afcd9c1ff3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "for root, dirs, files in os.walk(model_snapshot_path):\n",
    "    for file in files:\n",
    "        local_path = os.path.join(root, file)\n",
    "        s3_key = s3_model_prefix + '/' + os.path.relpath(local_path, model_snapshot_path)\n",
    "        s3_client.upload_file(local_path, bucket, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0527e45-c2da-477b-91fb-8d878a735ca2",
   "metadata": {},
   "source": [
    "### 3.模型部署准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb3b82-d8c5-41d3-86ac-6ebfeb7e01c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "* 推理容器镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269e86f-d50f-4857-a079-1a7a67f8e038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_image_uri = (\n",
    "    f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\"\n",
    ")\n",
    "\n",
    "# 中国区需要替换为下面的image_uri\n",
    "# inference_image_uri = (\n",
    "#     f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.22.1-deepspeed0.9.2-cu118\"\n",
    "# )\n",
    "\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faaf6561-3a6f-4482-8190-909980e9f8ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatglm2_deploy_code_path = Path(\"./LLM_chatglm2_deploy_code\")\n",
    "chatglm2_deploy_code_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f93edb-2a6a-4951-a4c6-4dbfdec4152b",
   "metadata": {},
   "source": [
    "* Entrypoint 脚本 model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba608c3-b401-4978-9c42-7bee13e209e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile LLM_chatglm2_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import logging\n",
    "\n",
    "def load_model(properties):\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location, trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained(model_location, trust_remote_code=True).half().cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer\n",
    "    if not model:\n",
    "        model, tokenizer = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    input_sentences = data[\"inputs\"]\n",
    "    params = data[\"parameters\"]\n",
    "    history = data[\"history\"]\n",
    "    \n",
    "    response, history = model.chat(tokenizer, input_sentences, history=history, **params)\n",
    "    \n",
    "    result = {\"outputs\": response, \"history\" : history}\n",
    "    return Output().add_as_json(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3b51f-03ee-4452-a974-aeccc68512e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "* serving.properties 配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af1838-0e93-416a-9f0a-27641d8736a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"option.s3url ==> s3://{bucket}/{s3_model_prefix}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ba16e-a749-4f6f-8566-d71b8afae8de",
   "metadata": {},
   "source": [
    "> 需要修改按照上述步骤的 s3url 修改 option.s3url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834150fe-a3cb-4d05-b479-ad73907cc6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile LLM_chatglm2_deploy_code/serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.s3url = s3://sagemaker-us-east-1-091166060467/LLM_chatglm2_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b6a5a6-8c04-4e2c-ab53-b0e96082c14d",
   "metadata": {},
   "source": [
    "* 将配置文件压缩后上传 S3 存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4560c8a0-6e24-4ee0-bd89-f6673c0b88b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "folder_path = 'LLM_chatglm2_deploy_code'\n",
    "output_filename = 'model.tar.gz'\n",
    "\n",
    "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "    tar.add(folder_path, arcname=os.path.basename(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef2e7b-411d-4b97-8d20-f36ab15a56b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95d83b-996e-4e7a-a84d-9b16406496be",
   "metadata": {},
   "source": [
    "### 4. 模型部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abc0dc85-2760-4132-9a60-9da0eb77ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "def create_model(model_name, model_s3_url):\n",
    "    model = Model(\n",
    "        image_uri=inference_image_uri,\n",
    "        model_data=model_s3_url,\n",
    "        role=role,\n",
    "        name=model_name,\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed2e95a-54ca-4b9e-a479-9d3da31079ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "def deploy_model(model, _endpoint_name):\n",
    "    model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.g4dn.2xlarge\",\n",
    "        endpoint_name=_endpoint_name\n",
    "    )\n",
    "    predictor = sagemaker.Predictor(\n",
    "        endpoint_name=_endpoint_name,\n",
    "        sagemaker_session=sess,\n",
    "        serializer=serializers.JSONSerializer(),\n",
    "        deserializer=deserializers.JSONDeserializer()\n",
    "    )\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dacdec-395c-4144-aa38-5e706faa1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "_model_name = name_from_base(f\"chatglm2\") # Append a timestamp to the provided string\n",
    "_model_s3_url = s3_code_artifact\n",
    "_endpoint_name = f\"{_model_name}-endpoint\"\n",
    "\n",
    "model = create_model(_model_name, _model_s3_url)\n",
    "predictor = deploy_model(model, _endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd0e0a-bd9c-41cd-9e0b-ce1641542076",
   "metadata": {},
   "source": [
    "### 5. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a82625f-cee0-409c-9060-be8620432ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "  \"max_length\": 8192,\n",
    "  \"temperature\": 0.01,\n",
    "  \"top_p\": 0.7,\n",
    "}\n",
    "\n",
    "history = [['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头','好的']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8af0c69-798d-4d95-bfc9-656ec970b76e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': '您好，我是气象专家智能对话助手小雷。我是一个计算机程序，通过人工智能技术来模拟人类思维和进行自然语言处理，能够回答您各种气象相关的问题。', 'history': [['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头', '好的'], ['你是谁？', '您好，我是气象专家智能对话助手小雷。我是一个计算机程序，通过人工智能技术来模拟人类思维和进行自然语言处理，能够回答您各种气象相关的问题。']]}\n"
     ]
    }
   ],
   "source": [
    "prompts1 = \"\"\"你是谁？\"\"\"\n",
    "\n",
    "reponse = predictor.predict(\n",
    "    {\n",
    "        \"inputs\" : prompts1, \n",
    "        \"parameters\": parameters,\n",
    "        \"history\" : history\n",
    "    }\n",
    ")\n",
    "history.extend(reponse['history'])\n",
    "\n",
    "print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ed16fed-0118-47e1-b5ee-a1539ad3d3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(reponse['outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff94d396-55f2-49d7-8eed-63333d478c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': '是的，北京属于温带季风气候，夏季气温较高，降雨量较大，通常夏季雨水较多。', 'history': [['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头', '好的'], ['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头', '好的'], ['你是谁？', '您好，我是气象专家智能对话助手小雷。我是一个计算机程序，通过人工智能技术来模拟人类思维和进行自然语言处理，能够回答您各种气象相关的问题。'], ['北京是不是夏天雨水比较多？', '是的，北京属于温带季风气候，夏季气温较高，降雨量较大，通常夏季雨水较多。']]}\n"
     ]
    }
   ],
   "source": [
    "prompts2 = \"\"\"北京是不是夏天雨水比较多？\"\"\"\n",
    "\n",
    "reponse = predictor.predict(\n",
    "    {\n",
    "        \"inputs\" : prompts2, \n",
    "        \"parameters\": parameters,\n",
    "        \"history\" : history\n",
    "    }\n",
    ")\n",
    "history.extend(reponse['history'])\n",
    "\n",
    "print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fee0392d-b767-4118-9da2-b3cd9639bf0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(reponse['outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "530f9208-eb09-4e59-b2db-504b056e0d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': '当然，我可以为您提供具体的例子。根据历史气象数据，北京夏季的降雨量通常在700-800毫米左右，而冬季的降雨量则相对较少，在500-600毫米左右。这个数据仅供参考，具体降雨量会受到多种因素的影响，如地形、季节、气候等。', 'history': [['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头', '好的'], ['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头', '好的'], ['你是谁？', '您好，我是气象专家智能对话助手小雷。我是一个计算机程序，通过人工智能技术来模拟人类思维和进行自然语言处理，能够回答您各种气象相关的问题。'], ['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头', '好的'], ['你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头', '好的'], ['你是谁？', '您好，我是气象专家智能对话助手小雷。我是一个计算机程序，通过人工智能技术来模拟人类思维和进行自然语言处理，能够回答您各种气象相关的问题。'], ['北京是不是夏天雨水比较多？', '是的，北京属于温带季风气候，夏季气温较高，降雨量较大，通常夏季雨水较多。'], ['你说的是真的吗？举个具体例子吧', '当然，我可以为您提供具体的例子。根据历史气象数据，北京夏季的降雨量通常在700-800毫米左右，而冬季的降雨量则相对较少，在500-600毫米左右。这个数据仅供参考，具体降雨量会受到多种因素的影响，如地形、季节、气候等。']]}\n"
     ]
    }
   ],
   "source": [
    "prompts3 = \"\"\"你说的是真的吗？举个具体例子吧\"\"\"\n",
    "\n",
    "reponse = predictor.predict(\n",
    "    {\n",
    "        \"inputs\" : prompts3, \n",
    "        \"parameters\": parameters,\n",
    "        \"history\" : history\n",
    "    }\n",
    ")\n",
    "\n",
    "print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d6c26f7-dc6a-4ac2-9e4b-8924ded7ddae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(reponse['outputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22883c-587b-4046-8ebb-08fb80a90db0",
   "metadata": {},
   "source": [
    "### 6. 通过 LangChain 构建对话机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a13ae8b0-4bf7-4df8-89aa-8453f8b7044c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install langchain boto3 -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58a5d1df-9e83-460a-8826-c81015c60398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import LLMChain, PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import json\n",
    "\n",
    "template = \"\"\"你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。但不能以人类身份提出问题，并进行自问自答。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头'.\n",
    "\n",
    "{chat_history}\n",
    "human: {human_input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5435a93c-91ec-4ed9-ba35-737f9e79f154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": model_kwargs,\n",
    "                \"history\":[]\n",
    "            })\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"outputs\"]\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "parameters = {\n",
    "  \"max_length\": 8192,\n",
    "  \"temperature\": 0.01,\n",
    "  \"top_p\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34efffc4-f227-4431-a6f1-f186b3bd3806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=SagemakerEndpoint(\n",
    "        endpoint_name=_endpoint_name,\n",
    "        # credentials_profile_name=\"credentials-profile-name\",\n",
    "        region_name=\"us-east-1\",\n",
    "        model_kwargs=parameters,\n",
    "        content_handler=content_handler\n",
    "    ),\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af22d1ec-1d11-4485-acf1-03c58cb93893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。但不能以人类身份提出问题，并进行自问自答。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头'.\n",
      "\n",
      "\n",
      "human: 你是谁\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'您好，我是气象专家智能对话助手小雷。我是一个由人工智能技术训练而成的计算机程序，能够提供各种气象知识和气象信息。'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"你是谁\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1820b6e-f6e3-420e-ace3-d3360e2f70cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。但不能以人类身份提出问题，并进行自问自答。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头'.\n",
      "\n",
      "Human: 你是谁\n",
      "AI: 您好，我是气象专家智能对话助手小雷。我是一个由人工智能技术训练而成的计算机程序，能够提供各种气象知识和气象信息。\n",
      "human: 北京是不是夏天雨水比较多？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'您好，我是气象专家智能对话助手小雷。北京属于温带季风气候，夏季炎热潮湿，降水量较多。在夏季，北京常常会遭遇暴雨、雷雨等极端天气，对人们的出行和生活造成一定的影响。'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"北京是不是夏天雨水比较多？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ffd1c79-55e9-4b50-bc7e-4783008c2d09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是气象专家智能对话助手小雷，了解各种专业的气象知识和气象信息，可以自由对话以及回答问题，像人类一样思考和表达。但不能以人类身份提出问题，并进行自问自答。当我向你提问时你必须使用，“您好，我是气象专家智能对话助手小雷”这句话作为开头'.\n",
      "\n",
      "Human: 你是谁\n",
      "AI: 您好，我是气象专家智能对话助手小雷。我是一个由人工智能技术训练而成的计算机程序，能够提供各种气象知识和气象信息。\n",
      "Human: 北京是不是夏天雨水比较多？\n",
      "AI: 您好，我是气象专家智能对话助手小雷。北京属于温带季风气候，夏季炎热潮湿，降水量较多。在夏季，北京常常会遭遇暴雨、雷雨等极端天气，对人们的出行和生活造成一定的影响。\n",
      "human: 你说的是真的吗？举个具体例子吧\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'好的，比如在 2021 年 7 月 23 日，北京市出现了强降雨天气，当天早晨至中午，北京市累计降水量达到了 178.7 毫米，最大小时雨强为 25.1 毫米。这场降雨导致市区交通瘫痪，许多道路积水严重，市民出行困难。此外，强降雨还引发了一系列的次生灾害，如雷击、山洪等。'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"你说的是真的吗？举个具体例子吧\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be408586",
   "metadata": {},
   "source": [
    "### 7. 结合向量数据库私域数据构建专业知识问答系统"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b02395",
   "metadata": {},
   "source": [
    "#### 7.1 部署 Embedding 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "675ea605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface-hub -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47cd1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# import boto3\n",
    "# import os\n",
    "# from sagemaker import image_uris\n",
    "\n",
    "# role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "# sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "# bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "# region = sess._region_name\n",
    "# account_id = sess.account_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a71421",
   "metadata": {},
   "source": [
    "* 下载 Embedding 模型并拷贝至 S3 存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "194ef0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_embedding_model_path = Path(\"./embedding_model\")\n",
    "local_embedding_model_path.mkdir(exist_ok=True)\n",
    "embedding_model_name = \"moka-ai/m3e-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d858c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_download(repo_id=embedding_model_name, cache_dir=local_embedding_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_embedding_model_prefix = \"embedding_model\"  # folder where model checkpoint will go\n",
    "embedding_model_snapshot_path = list(local_embedding_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_embedding_code_prefix = \"embedding_deploy_code\"\n",
    "\n",
    "print(f\"s3_embedding_code_prefix: {s3_embedding_model_prefix}\")\n",
    "print(f\"embedding_model_snapshot_path: {embedding_model_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e96b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "for root, dirs, files in os.walk(embedding_model_snapshot_path):\n",
    "    for file in files:\n",
    "        local_path = os.path.join(root, file)\n",
    "        s3_key = s3_embedding_model_prefix + '/' + os.path.relpath(local_path, embedding_model_snapshot_path)\n",
    "        s3_client.upload_file(local_path, bucket, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89064f0",
   "metadata": {},
   "source": [
    "* 模型部署准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2152489",
   "metadata": {},
   "source": [
    ">推理容器镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4144ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_image_uri = (\n",
    "#     f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\"\n",
    "# )\n",
    "\n",
    "# 中国区需要替换为下面的image_uri\n",
    "# inference_image_uri = (\n",
    "#     f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.22.1-deepspeed0.9.2-cu118\"\n",
    "# )\n",
    "\n",
    "# print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9025887",
   "metadata": {},
   "source": [
    "> Entrypoint 脚本 model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96003aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_deploy_code_path = Path(\"./embedding_deploy_code\")\n",
    "embedding_deploy_code_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd545d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile embedding_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'--device={device}')\n",
    "\n",
    "def load_model(properties):\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location)\n",
    "    \n",
    "    model = AutoModel.from_pretrained(model_location)\n",
    "    model.to(device) \n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0].to(device) #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float().to(device)\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer\n",
    "    if not model:\n",
    "        model, tokenizer = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    input_sentences = data[\"inputs\"]\n",
    "    logging.info(f\"inputs: {input_sentences}\")\n",
    "    \n",
    "    encoded_input = tokenizer(input_sentences, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask']).to(device).cpu().numpy()\n",
    "\n",
    "    \n",
    "    result = {\"sentence_embeddings\": sentence_embeddings}\n",
    "    return Output().add_as_json(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef48f80",
   "metadata": {},
   "source": [
    ">serving.properties 配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"option.s3url ==> s3://{bucket}/{s3_embedding_model_prefix}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e96606",
   "metadata": {},
   "source": [
    ">需要修改按照上述步骤的 s3url 修改 option.s3url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile embedding_deploy_code/serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.s3url = s3://sagemaker-us-east-1-091166060467/embedding_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961babb5",
   "metadata": {},
   "source": [
    ">将配置文件压缩后上传 S3 存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "985d52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "folder_path = 'embedding_deploy_code'\n",
    "output_filename = 'embedding_model.tar.gz'\n",
    "\n",
    "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "    tar.add(folder_path, arcname=os.path.basename(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_embedding_code_artifact = sess.upload_data(\"embedding_model.tar.gz\", bucket, s3_embedding_model_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_embedding_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda4f7e",
   "metadata": {},
   "source": [
    "* 模型部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45792342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "def create_model(embedding_model_name, embedding_model_s3_url):\n",
    "    model = Model(\n",
    "        image_uri=inference_image_uri,\n",
    "        model_data=embedding_model_s3_url,\n",
    "        role=role,\n",
    "        name=embedding_model_name,\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8419d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "def deploy_model(embedding_model, _embedding_endpoint_name):\n",
    "    embedding_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.g4dn.2xlarge\",\n",
    "        endpoint_name=_embedding_endpoint_name\n",
    "    )\n",
    "    predictor = sagemaker.Predictor(\n",
    "        endpoint_name=_embedding_endpoint_name,\n",
    "        sagemaker_session=sess,\n",
    "        serializer=serializers.JSONSerializer(),\n",
    "        deserializer=deserializers.JSONDeserializer()\n",
    "    )\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88669423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "_embedding_model_name = name_from_base(f\"embedding\") # Append a timestamp to the provided string\n",
    "_embedding_model_s3_url = s3_embedding_code_artifact\n",
    "_embedding_endpoint_name = f\"{_embedding_model_name}-endpoint\"\n",
    "\n",
    "embedding_model = create_model(_embedding_model_name, _embedding_model_s3_url)\n",
    "predictor = deploy_model(embedding_model, _embedding_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec91a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence_embeddings': [[0.1661466658115387, 0.21069838106632233, 0.037976332008838654, -1.0181440114974976, 0.9220373630523682, -0.34364432096481323, -0.3254205286502838, 0.3959977924823761, -0.2856331765651703, 0.007160128094255924, 1.3837165832519531, -0.12990392744541168, 0.08019100874662399, -0.34041914343833923, -0.9665930271148682, 0.48589572310447693, 0.5809509754180908, 0.5983567833900452, -0.4446329176425934, -0.5546057224273682, 0.6520602703094482, -0.4992707669734955, -1.0214598178863525, 1.2074915170669556, -0.3740547299385071, 0.12379223853349686, 0.3542039096355438, -0.5372006297111511, -0.227334126830101, -0.3129536807537079, 1.1523760557174683, -0.4037540555000305, -0.4717123806476593, -0.135154590010643, -0.13646675646305084, 0.6498154997825623, 0.656075119972229, -0.10279015451669693, 1.042426347732544, 1.0639843940734863, 0.18004818260669708, 0.3613552749156952, -0.2584298253059387, -0.1127227321267128, 0.14170494675636292, 0.1576465666294098, 0.2994483411312103, 0.5560096502304077, -0.17168015241622925, 0.946146547794342, -0.10559535026550293, 6.927255630493164, -0.058558907359838486, 0.9732223153114319, -0.24943405389785767, 0.7020077109336853, -0.634909451007843, -0.4778747260570526, 0.022788872942328453, 0.455755352973938, 0.3818485140800476, -0.7403342723846436, -0.29903271794319153, -0.8725693225860596, -0.6075965762138367, 0.13302196562290192, -1.6292327642440796, -0.6532219052314758, 1.1325167417526245, -1.7503150701522827, 1.0369640588760376, -0.44440680742263794, -0.7424330115318298, -0.37242233753204346, 0.14010150730609894, -0.17729346454143524, 1.040168046951294, 0.8009641766548157, -0.0007395004504360259, 0.08093128353357315, 0.7657492160797119, 0.3422805070877075, -0.0006716151838190854, 0.18793527781963348, -0.885890007019043, -0.655318558216095, 0.05349377542734146, 0.23434308171272278, 0.8355284333229065, 0.46515268087387085, -1.5521262884140015, -0.20530720055103302, -1.1695137023925781, -0.6965190172195435, -0.14520396292209625, -0.14475968480110168, 0.9523837566375732, -0.7841643691062927, -0.548043429851532, -0.29915159940719604, -0.3742947280406952, 0.26208311319351196, 0.057177186012268066, -0.689233124256134, 0.5036850571632385, 0.6703687310218811, -0.7119877338409424, 0.3398834764957428, 0.5670681595802307, 0.12421086430549622, -0.18782316148281097, -0.16329337656497955, 0.4481795132160187, 1.0586953163146973, -0.8376115560531616, -0.28484150767326355, -0.26623910665512085, 0.6319558024406433, 0.7990561127662659, -0.13862423598766327, 0.05379175394773483, 0.7494670748710632, -0.9395486116409302, -0.7112375497817993, 0.40812060236930847, -0.43268251419067383, -0.13601547479629517, 0.4872879683971405, -0.009786351583898067, 0.7038221955299377, 0.7043520212173462, -0.2923561632633209, -0.4201553165912628, 0.6173248887062073, -0.20465515553951263, -0.5494897365570068, 0.40156251192092896, -0.777519166469574, -1.326821208000183, -0.37726595997810364, -0.028083885088562965, 0.1915605068206787, 0.5554723739624023, -0.655430793762207, -0.48910850286483765, 0.4888584315776825, 0.12562616169452667, 0.05783761665225029, 1.1371575593948364, -0.6633169054985046, -0.2156042754650116, -0.26965242624282837, -0.46235448122024536, 0.35281237959861755, 0.1864934265613556, -0.0425717867910862, -0.2981891632080078, 0.0030987481586635113, -1.2366867065429688, -0.6348033547401428, -0.38237273693084717, -0.04364145174622536, 0.2631041705608368, -0.002203180454671383, 0.5063627362251282, -0.40397384762763977, 0.12320392578840256, -0.566012978553772, -0.6996517181396484, 0.0777001827955246, -0.4155539274215698, -0.002496558940038085, -0.04647127911448479, -0.022825326770544052, -0.589482843875885, -0.8690017461776733, -0.47494685649871826, 0.6444123387336731, -0.7168005704879761, -0.6538392305374146, -1.063523769378662, 0.5946371555328369, 0.15878009796142578, -0.17549267411231995, -0.6140220761299133, -0.4323965907096863, -0.8952243328094482, 0.22945687174797058, 0.5548078417778015, 0.18862520158290863, -0.8891199231147766, -0.9697065949440002, -0.6574327945709229, -1.0809056758880615, 1.3671923875808716, 1.0045068264007568, 0.10631048679351807, 0.1794881671667099, -0.8266115188598633, 0.07060519605875015, 0.9105213284492493, -0.4770994484424591, 0.24805809557437897, 0.8183470368385315, -0.28262487053871155, 0.411180704832077, 0.43032750487327576, 0.743057131767273, 0.34828028082847595, -0.17301489412784576, -0.4499514400959015, -0.4944240152835846, -0.19234032928943634, 0.7140926122665405, -0.25204938650131226, 0.05423940345644951, -1.4746042490005493, 0.287924200296402, -0.29234960675239563, -0.1581565886735916, 1.0035268068313599, -0.9071570038795471, -0.8057669997215271, -0.23250551521778107, -0.8932037949562073, -0.2395799458026886, 0.5789806246757507, 0.027268338948488235, -0.38048604130744934, -0.576947033405304, 0.867975115776062, -1.0108001232147217, -0.3257752060890198, -0.5974627137184143, 1.0420479774475098, 0.9654474854469299, 0.16991166770458221, 1.0513567924499512, -0.15356062352657318, -0.6792246699333191, -1.204502820968628, 0.5748981833457947, 2.222416400909424, -0.8121306300163269, 0.0976906344294548, -0.10423003137111664, -0.42701688408851624, -0.7691418528556824, -0.34144407510757446, -0.15889596939086914, 0.15691518783569336, 0.2926922142505646, 0.1800922304391861, -1.40475332736969, -0.636055588722229, -0.4736451506614685, -0.8505674004554749, -0.46236515045166016, 0.6398199796676636, -0.04433088377118111, -0.11009099334478378, -0.6191612482070923, 0.6803364157676697, 0.5403003096580505, 0.23383893072605133, -0.14353521168231964, -0.5181370973587036, -0.3468032777309418, -0.14383496344089508, -0.5730654001235962, 0.4051564633846283, 1.129024863243103, -0.27528372406959534, -0.4083368480205536, 0.4170030951499939, 0.5110567212104797, 0.5566977262496948, 0.3288891613483429, 0.010549385100603104, -0.9752616882324219, -0.30268046259880066, -0.18621762096881866, 0.2917030453681946, 0.1170518696308136, -0.07931733876466751, -0.6741198301315308, -0.04050394520163536, 0.6123601198196411, -0.005276795011013746, -0.6503778100013733, -0.5180206894874573, -0.5805799961090088, 0.6960919499397278, 1.0624130964279175, 1.4144313335418701, -0.11100082099437714, -1.1891517639160156, 1.2319872379302979, 0.028920363634824753, -0.48934414982795715, 0.4282384216785431, -0.5396141409873962, -1.123792290687561, 0.7245404720306396, -0.13754799962043762, 0.39245012402534485, -0.5315096974372864, 0.43619659543037415, -1.4601285457611084, -0.7597828507423401, 0.01837345026433468, -0.49306347966194153, -0.0015449007041752338, 0.35392341017723083, -0.46630483865737915, -0.07493975758552551, -0.007739645428955555, -0.8235931396484375, 0.1483650803565979, -0.28540533781051636, 1.5200167894363403, 0.26422709226608276, 0.3740837275981903, 0.8004319667816162, 0.5139592885971069, 0.8255723118782043, 0.9567019939422607, 0.778046727180481, -0.138483926653862, 0.7326632738113403, 0.6822856664657593, 0.16583023965358734, -0.06463222205638885, 0.08346497267484665, 0.13257458806037903, 1.1776903867721558, -0.1755777895450592, -0.5866687297821045, -0.2713889479637146, 0.31062793731689453, 0.30307164788246155, -0.4400525987148285, 0.29443320631980896, -0.6409071683883667, 0.25589659810066223, -0.12626320123672485, 0.17183111608028412, 0.2641235589981079, -0.32705366611480713, -0.6566299796104431, -0.4875546097755432, 1.0360209941864014, -0.6581541299819946, -0.3462078869342804, 0.36083629727363586, -0.16658329963684082, 0.5728822946548462, 0.060508012771606445, 0.8941788077354431, 0.7088201642036438, -0.2930065095424652, -1.3908230066299438, -0.5266095399856567, -0.20743168890476227, -0.21930448710918427, -0.31346145272254944, 0.7639394402503967, -0.36867472529411316, 0.0474039651453495, -1.3960031270980835, 0.6518307328224182, 0.24348808825016022, 1.0036118030548096, -0.4447272717952728, 0.09984052926301956, 0.19226182997226715, -0.6999272108078003, 0.8117688298225403, -0.21390418708324432, -0.21966832876205444, 1.421057105064392, -0.5619987845420837, 0.8271453380584717, 0.5011010766029358, -0.009314214810729027, -0.19537582993507385, -0.16996735334396362, -1.1881356239318848, -0.9355959296226501, -0.042469099164009094, -1.054329514503479, -0.23055674135684967, 0.07134426385164261, 0.1295299082994461, 0.3867059648036957, 0.11549533903598785, 0.7855263352394104, 0.42998984456062317, 0.05312133952975273, -0.10955822467803955, 0.08909521996974945, -1.1318608522415161, -0.4064803421497345, 0.38983121514320374, 1.2439109086990356, 0.3382221758365631, 0.8350781798362732, -0.36215105652809143, -0.24999548494815826, -0.03692237660288811, -1.0554603338241577, -0.12023996561765671, -0.7811402678489685, -0.71958327293396, 0.09924645721912384, -0.15075789391994476, -0.619766891002655, -0.4562375247478485, 0.11739799380302429, -0.46572455763816833, -0.09771033376455307, 0.2670486867427826, 1.0391924381256104, 0.80706787109375, 0.2981792986392975, -0.26754918694496155, -0.5316256880760193, -0.30804744362831116, 0.4761214852333069, -0.03561268001794815, 0.5229201316833496, -0.19785740971565247, 0.3618966341018677, -1.0501818656921387, 0.8230329155921936, 0.6801429986953735, -0.3439488410949707, -0.1397118717432022, -0.22357994318008423, 0.5873780846595764, -1.2185306549072266, 0.31498652696609497, 0.608010470867157, -0.8244413137435913, -0.24085943400859833, 0.45103970170021057, -0.4405915141105652, -0.7358015179634094, 0.4409252405166626, 0.6467793583869934, 0.29553407430648804, 0.032701730728149414, 0.004341189283877611, -0.7928359508514404, 0.33081042766571045, -0.16195045411586761, -0.3380264341831207, -0.34630081057548523, 0.6175057291984558, -0.5643488168716431, -0.5857059359550476, 0.43660131096839905, -0.961715042591095, 0.2910701036453247, 0.97422194480896, 0.16573640704154968, 0.34644076228141785, -0.1948065161705017, 0.7976368069648743, -0.15790124237537384, -0.5656875967979431, 1.2332885265350342, 0.8001383543014526, 0.28009334206581116, -0.42884963750839233, -0.19906994700431824, 0.6025729775428772, -0.19084253907203674, -1.2122894525527954, -0.9198094606399536, 0.8047552704811096, -0.4620567262172699, -0.12016784399747849, -0.300083190202713, -1.343237042427063, -0.28322261571884155, -0.35638710856437683, -0.8356150388717651, 0.5888755321502686, -0.6029084920883179, -1.3461979627609253, 0.09308972954750061, 0.33939629793167114, -1.0204957723617554, -0.10987845063209534, -0.6850948929786682, 0.17749962210655212, 0.4897193908691406, -0.6991078853607178, 0.5041924118995667, 0.4168330430984497, -0.5248726606369019, 0.6039782166481018, 1.2039951086044312, -0.001099667977541685, -0.6572234034538269, 0.034498926252126694, -0.8002697229385376, 0.2911553978919983, 0.9897288084030151, 0.3157554566860199, -0.605329692363739, -0.47005870938301086, 1.2970079183578491, -0.10976214706897736, -0.09863734245300293, -0.8518608212471008, -0.4982444941997528, 1.0059914588928223, 0.20521053671836853, 0.5890137553215027, -0.22275905311107635, 0.0549921840429306, 0.5588011145591736, -0.15241974592208862, 0.294291228055954, 0.7412388920783997, 0.10497082769870758, 0.1637508124113083, 1.2770652770996094, -0.8155688047409058, -0.9163777232170105, 0.2125132828950882, -0.4180675745010376, 0.306784987449646, 0.1520315557718277, -0.07944492995738983, -0.6426304578781128, -1.3337481021881104, -1.2385268211364746, 0.4849894642829895, 0.3209673762321472, 1.0033174753189087, -0.6074128746986389, -0.7163928151130676, -1.3062223196029663, -0.24625422060489655, -0.3925105631351471, 0.8757531642913818, 0.5157774686813354, -1.360013723373413, 0.5866554379463196, -1.0530130863189697, 0.5264014005661011, 0.0392504557967186, 0.6571938395500183, -1.2829463481903076, -0.5349023938179016, 0.7513927221298218, -0.08101534098386765, -0.14260849356651306, -1.0479711294174194, -0.7897487878799438, -1.1451359987258911, -1.17008638381958, 0.2633154094219208, -0.5575655102729797, 0.041663311421871185, 0.8505111932754517, 0.30440229177474976, -0.38653096556663513, 0.2274673581123352, 0.30796873569488525, 0.15395884215831757, 0.06425197422504425, 0.0280071422457695, -0.48181426525115967, -0.2907046973705292, 0.12263240665197372, 0.3859039843082428, 0.7994844913482666, 1.3494384288787842, -1.3825162649154663, -0.9045734405517578, -0.45988497138023376, 0.23046237230300903, 0.5446493029594421, -0.5814500451087952, 0.863400399684906, -0.3160713016986847, -0.6724010109901428, 0.3930037319660187, 0.16310831904411316, 0.990433931350708, -0.12544311583042145, 0.8087120652198792, -0.3230319321155548, 0.09842615574598312, -0.6887563467025757, 0.4234107732772827, 0.3000849485397339, -0.060983363538980484, 0.8770372271537781, -2.2027890736353584e-05, 0.24590428173542023, -0.585614800453186, 1.7207361459732056, 0.3271371126174927, 0.2426174134016037, 0.2431841492652893, -1.263091802597046, 1.2855799198150635, 1.11436927318573, -0.6669850945472717, 1.20980966091156, -0.11821630597114563, -0.7327855825424194, 0.3896067440509796, 0.29460781812667847, 0.5868483185768127, 0.10207423567771912, -0.2836973965167999, -0.20614227652549744, 0.0035455801989883184, -0.2689765691757202, 0.4447025656700134, 2.227207899093628, 0.98231440782547, 1.3223729133605957, 0.2772962749004364, 0.37316569685935974, -0.5040112137794495, 0.18515892326831818, 0.32963624596595764, 0.315682053565979, 0.5762279033660889, 0.2981826961040497, -0.005958096124231815, -1.1851032972335815, 0.9404360055923462, 1.707452416419983, 0.22695176303386688, -0.9959439039230347, 0.11266085505485535, 1.0877432823181152, -0.011585782282054424, 1.72776198387146, 0.4598935544490814, 0.05890391767024994, -0.35422849655151367, 0.9945249557495117, -0.9096594452857971, 1.194907307624817, -0.43809425830841064, -1.3379566669464111, 0.6754562854766846, 0.6603887677192688, 0.10808753967285156, -0.830809473991394, -0.7544049024581909, -0.41911253333091736, -0.8851705193519592, 1.5906658172607422, -0.6829529404640198, 0.09634657204151154, -0.8639903664588928, 0.6958164572715759, 0.8636446595191956, 0.534761369228363, 1.1229020357131958, 0.22716385126113892, 0.9347944259643555, 0.7893245816230774, -0.8984871506690979, -0.08221694082021713, -0.4455609917640686, 0.2554074823856354, 0.29855072498321533, -0.1749916523694992, -0.7226664423942566, -1.233447551727295, -0.7831069827079773, 0.6051753759384155, -1.3278844356536865, 0.022528192028403282, -0.4854367673397064, -1.037666916847229, 0.3496573865413666, -0.3799947202205658, 0.847694456577301, 0.5780244469642639, 0.7575476169586182, 0.32246798276901245, 0.6631850004196167, -0.6542755961418152, 2.125046968460083, -0.18271437287330627, 0.30112192034721375, -0.7813501954078674, -0.46863406896591187, 0.752200186252594, 0.5874632596969604, -0.5018614530563354, -0.33454030752182007, -0.48998183012008667, 0.7139965891838074, -0.6429887413978577, 0.10066629946231842, 0.008157266303896904, -0.1843840479850769, -0.9712409377098083, -0.6504637598991394, 0.48771363496780396, -1.1677600145339966, 0.9686588048934937, -0.2164497673511505, -0.4748572111129761, 0.2905125916004181, 0.9782673120498657, 0.5916362404823303, 0.19356490671634674, -0.5583935379981995, 0.5133244395256042, -0.14369970560073853, 0.14084063470363617, 1.0427708625793457, 0.7438322901725769, 1.1075727939605713, 0.35157573223114014, -0.557633101940155, -0.08028081804513931, -1.3754154443740845, 0.2966166138648987, -1.1785387992858887, -0.08485109359025955, 0.9022236466407776, 0.3872579038143158, -0.5331937670707703, 0.3695618808269501, 0.5397348403930664, 0.11019210517406464, -0.06843990832567215, 0.7754726409912109, -0.17328310012817383, -0.9062473773956299, -0.5438664555549622, -0.3346855044364929, 0.9700244665145874, 0.5531673431396484, 0.8873579502105713, -0.6239073872566223, 0.3561555743217468, -0.30955082178115845, -0.28053590655326843, 1.4546958208084106, -0.9266250729560852, 0.10338649153709412, -1.0833630561828613, 0.13585875928401947, -0.2632124722003937, -0.18967054784297943, -0.24049416184425354, 0.17885713279247284, -1.1434032917022705, -0.4972323775291443, -1.2498902082443237, -0.5950005054473877, 0.00944016594439745]]}\n"
     ]
    }
   ],
   "source": [
    "# Embedding 模型验证\n",
    "\n",
    "prompts = \"\"\"\n",
    "北京是不是夏天雨水比较多？\n",
    "\"\"\"\n",
    "\n",
    "reponse = predictor.predict(\n",
    "    {\n",
    "        \"inputs\" : prompts\n",
    "    }\n",
    ")\n",
    "\n",
    "print(reponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc63ad",
   "metadata": {},
   "source": [
    "#### 7.2 通过 LangChain 使用 Embedding 模型处理文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cec298b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "import json\n",
    "\n",
    "class EmbeddingContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "    \n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"sentence_embeddings\"]\n",
    "    \n",
    "embedding_content_handler = EmbeddingContentHandler()\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    # credentials_profile_name=\"credentials-profile-name\",\n",
    "    endpoint_name =_embedding_endpoint_name,\n",
    "    region_name = \"us-east-1\",\n",
    "    content_handler = embedding_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c05481a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证 LangChain 调用 Embedding 模型\n",
    "\n",
    "# query_result = embeddings.embed_query(\"query\")\n",
    "\n",
    "# doc_results = embeddings.embed_documents(['content1', 'content2'])\n",
    "\n",
    "# print(query_result, '\\n\\n', doc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb90719",
   "metadata": {},
   "source": [
    "#### 7.3 私域文档处理及私域文档 Embedding 处理后存入 Chroma 向量数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4da77",
   "metadata": {},
   "source": [
    "* 私域文档加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b92f95-9922-4c9f-a056-ad9295289d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/terrificdm/llm-sagemaker-examples\n",
    "!mv llm-sagemaker-examples/content ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "directory = './content'\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory, show_progress=True, loader_cls=TextLoader)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b473f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "count = 0\n",
    "for doc in documents:\n",
    "    for line in doc.page_content.split('\\n'):\n",
    "        if line.startswith('Question'):\n",
    "            count += 1\n",
    "\n",
    "print(f'Total number of questions: {count}')\n",
    "pprint.pprint(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a68283",
   "metadata": {},
   "source": [
    "* 文档切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"Question\"], \n",
    "    chunk_size = 0,\n",
    "    chunk_overlap = 0,\n",
    "    length_function = len,\n",
    "    # add_start_index = True,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "pprint.pprint(docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a736792",
   "metadata": {},
   "source": [
    "* 部署 [Chroma 向量数据库](https://docs.trychroma.com/)，及私域文档 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea0fa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f0600d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding_function = embeddings\n",
    "\n",
    "# Non-persistence Chroma, you can use Chroma in persistent way as described in its documents. \n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fa4e61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question：沙穹秘境是什么类型的游戏？\n",
      "Answer：沙穹秘境是一款冒险类的开放世界游戏。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 验证通过 embedding 检索私域数据\n",
    "\n",
    "query = \"沙穹秘境是什么\"\n",
    "content = db.similarity_search(query, k=1)\n",
    "\n",
    "print(content[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9098a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR Retriever\n",
    "\n",
    "# retriever = db.as_retriever(search_type=\"mmr\")\n",
    "# retriever.get_relevant_documents(query)[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcda59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "\n",
    "# client = chromadb.Client()\n",
    "# client.list_collections()\n",
    "# collection = client.get_collection(\"langchain\")\n",
    "# collection.count()\n",
    "\n",
    "# collection.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69889cf1",
   "metadata": {},
   "source": [
    "#### 7.4 构建专业问答机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e980773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "import json\n",
    "\n",
    "human = \"用户\"\n",
    "aibot = \"CelestialSandsBot\"\n",
    "\n",
    "template = \"\"\"\n",
    "你是沙穹秘境(Celestial Sands Game)的专属智能客服{aibot}，你不允许谈论其他游戏。\n",
    "你是一个非常专业的游戏客服，请从下面三个反引号中的文档中提取并理解相关内容形成答案，以简洁明了的方式回答{human}问题。\n",
    "你不能随意假设游戏，你不能随意编造答案，如果你不知道问题答案，你就回答“对不起，我不知道。”\n",
    "如果三个反引号中的文档和问题无关，你就回答“抱歉，我的资料库中没有相关内容，可以请您把问题描述的更具体些吗？”。\n",
    "\n",
    "```{context}```\n",
    "\n",
    "{chat_history}\n",
    "{human}: {human_input}\n",
    "{aibot}:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"chat_history\", \"human_input\", \"human\", \"aibot\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\", ai_prefix=aibot, human_prefix=human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8fe45d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlmContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        # input_str = json.dumps({prompt: prompt, **model_kwargs})\n",
    "        input_str = json.dumps({\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": model_kwargs,\n",
    "                \"history\":[]\n",
    "            })\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"outputs\"]\n",
    "\n",
    "llm_content_handler = LlmContentHandler()\n",
    "\n",
    "parameters = {\n",
    "  \"max_length\": 8192,\n",
    "  \"temperature\": 0.01,\n",
    "  \"top_p\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e51e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = load_qa_chain(\n",
    "    llm=SagemakerEndpoint(\n",
    "        endpoint_name=_endpoint_name,\n",
    "        # credentials_profile_name=\"credentials-profile-name\",\n",
    "        region_name=\"us-east-1\",\n",
    "        model_kwargs=parameters,\n",
    "        content_handler=llm_content_handler\n",
    "    ), \n",
    "    chain_type=\"stuff\", \n",
    "    # memory=memory, \n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "stop = [\"\\n\"+human, \"\\n\\n\"+human] # Chatglm 模型输出默认没有截断符，在这里使用 langchain.llms.util 中的 enforce_stop_tokens 实现输出截断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "abc05c84-c62d-4d2c-9d22-952e1e9cd8da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_answer(content, query, chat_history=None):\n",
    "    \n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "        \n",
    "    llm_inputs = {\n",
    "        \"input_documents\": content, \n",
    "        \"human_input\": query, \n",
    "        \"chat_history\": chat_history, \n",
    "        \"human\": human, \n",
    "        \"aibot\": aibot\n",
    "    }\n",
    "    \n",
    "    answer = llm_chain(llm_inputs, return_only_outputs=True)\n",
    "    return answer\n",
    "\n",
    "def process_query(query, chat_history=None):\n",
    "    \n",
    "    # content = db.similarity_search(query, k=3)\n",
    "    retriever = db.as_retriever(search_type=\"mmr\")\n",
    "    content = retriever.get_relevant_documents(query)\n",
    "\n",
    "    answer = get_answer(content, query, chat_history)['output_text']\n",
    "    answer = enforce_stop_tokens(answer, stop)\n",
    "    print(answer)\n",
    "\n",
    "    memory.chat_memory.add_user_message(query)\n",
    "    memory.chat_memory.add_ai_message(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3730346b-150f-4e69-901c-d2cca3f8afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个沙穹秘境的专属智能客服CelestialSandsBot，我的职责是回答关于游戏的问题。\n"
     ]
    }
   ],
   "source": [
    "query = \"你是谁？\"\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23920b5e-24c0-4a2f-ac22-13e42feb91d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沙穹秘境是一款非常有趣的开放世界游戏，拥有精彩的战斗系统和丰富的游戏内容，深受玩家的喜爱。\n"
     ]
    }
   ],
   "source": [
    "query = \"沙穹秘境好玩吗？\"\n",
    "chat_history = memory.load_memory_variables({})['chat_history']\n",
    "process_query(query, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4dad5823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沙穹秘境中有各种各样的商店，包括武器店、防具店、杂货店、宠物店等等。\n"
     ]
    }
   ],
   "source": [
    "query = \"沙穹秘境中有哪些商店？\"\n",
    "chat_history = memory.load_memory_variables({})['chat_history']\n",
    "process_query(query, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35be7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在沙穹秘境中，玩家可以通过攻击其他玩家来获取伤害和经验值。攻击别人需要消耗魔法或能量值，并有一定概率触发暴击效果，造成更高的伤害。同时，攻击别人也会产生不良后果，如被对方反击、减速等。因此，在游戏中，玩家需要谨慎选择攻击对象，并合理运用自己的技能和资源。\n"
     ]
    }
   ],
   "source": [
    "query = \"如何攻击别人？\"\n",
    "chat_history = memory.load_memory_variables({})['chat_history']\n",
    "process_query(query, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "556b55af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': '用户: 你是谁？\\nCelestialSandsBot: 我是一个沙穹秘境的专属智能客服CelestialSandsBot，我的职责是回答关于游戏的问题。\\n用户: 沙穹秘境好玩吗？\\nCelestialSandsBot: 沙穹秘境是一款非常有趣的开放世界游戏，拥有精彩的战斗系统和丰富的游戏内容，深受玩家的喜爱。\\n用户: 沙穹秘境中有哪些商店？\\nCelestialSandsBot: 沙穹秘境中有各种各样的商店，包括武器店、防具店、杂货店、宠物店等等。\\n用户: 如何攻击别人？\\nCelestialSandsBot: 在沙穹秘境中，玩家可以通过攻击其他玩家来获取伤害和经验值。攻击别人需要消耗魔法或能量值，并有一定概率触发暴击效果，造成更高的伤害。同时，攻击别人也会产生不良后果，如被对方反击、减速等。因此，在游戏中，玩家需要谨慎选择攻击对象，并合理运用自己的技能和资源。'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
