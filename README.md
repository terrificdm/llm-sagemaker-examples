# LLM on AWS SageMaker Examples
* chatglm2-langchain-vetordb_deploy.ipynb is an example for deploying [THUDM/chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b) with vectorDB [Chroma](https://docs.trychroma.com/) and [LangChain](https://python.langchain.com) on AWS SageMaker Platform, targeting at building private query-answer system powered by vectorDB and LLM.

* baichuan13b-langchain-vetordb_deploy.ipynb is an example for deploying [baichuan-inc/Baichuan-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat) with vectorDB [Chroma](https://docs.trychroma.com/) and [LangChain](https://python.langchain.com)(ducument processing only) on AWS SageMaker Platform, targeting at building private query-answer system powered by vectorDB and LLM.

* chatglm3-streaming-deploy.ipynb is a streaming outputs example deployed on SageMaker.  

* bedrock-langchain-vectordb.ipynb is an example for combining bedrock-claude with vectorDB for llm+RAG usecase.  

* bedrock-knowledgebase.ipynb is an example for combining bedrock-claude with KnowledgeBase for llm+RAG usecase.

> Stay tuned ...
